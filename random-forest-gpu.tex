\documentclass{lug}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{color}
\usepackage{pseudocode}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\title{A Parallel Implementation of Random Forest}
\author{Lou Brand and Xun Li}
\institute{\textbf{Department of Computer Science\\Colorado School of Mines}}
\date{\today}

\begin{document}

\section{Background}
\frame{
    \frametitle{Random Forest}
    \begin{center}
        \includegraphics[scale=0.6]{images/random-forest-simplified.jpg}\\
        \textbf{Key:} Versatility
    \end{center}
}

\frame{
    \frametitle{gcForest}
    \begin{center}
        \includegraphics[scale=0.3]{images/gcForest.png}\\
        Find a quote from gcForest about ``easily'' parallelized. How did we misinterpret this initially? Where did this lead us? 
    \end{center}
}
\frame{
    \frametitle{Applications}
    \begin{center}
        \includegraphics[scale=0.75]{images/cifar1.jpg}\\ 
        Face perception, image tagging, regression, classification, etc.
    \end{center}
}

\frame{
    \frametitle{An Insight into Node Splitting}
    \begin{itemize}[<+->]
        \item Focus on the elemental operation of the random forest algorithm
        \item Keep in mind.. tree algorithms are inherently difficult
            \begin{enumerate}
                \item Load balancing
                \item Dynamic irregular memory accesses
                \item As we get lower in the tree == many small kernels
            \end{enumerate}
    \end{itemize}
    \pause
    Can we use parallel programming on the CPU/GPU to give some insights into node splitting?
    Explicitly mention why we focus on node splitting and not the entire Random Forest algorithm.
}

\section{Approach}
\frame{
    \frametitle{Node Splitting}
    \begin{center}
        \includegraphics[scale=0.5]{images/node-split.png}\\
        \textbf{Goal}: Optimize splitting of the nodes using parallel programming techniques 
    \end{center}
}

\frame{
    \frametitle{Maximize Information Gain}
    \begin{center}
        Calculate Gini Index 
        $$ GI=1- \sum_{j=0}^{M}(\frac{C_j}{W})^2 $$
        $$ IG=GI_P-\frac{N_L}{N}GI_L-\frac{N_R}{N}GI_R $$
        Splitting value $= argmax(IG_{feature})$
    \end{center}
}

\frame{
    \frametitle{The Algorithm}
    \begin{pseudocode}{SplittingNodeNaive}{features} 
        1\quad \FOR k \GETS 0 \TO num(features)\\
        3\quad \quad ComputeHistogramForEachNode\\
        4\quad \quad ComputeGiniIndex\\
        5\quad \quad ComputeInformationGain\\
        6\quad split = argmax(InformationGain)\\
        7\quad \RETURN{split}
    \end{pseudocode}
}

\frame{
    \frametitle{Serial CPU Baseline}
    Talk about data. Put in timing data.
}

\section{Implementation}

\frame{
    \frametitle{Parallel Implementation Considerations}
    \begin{itemize}[<+->]
        \item Block Interleaving - Partition for atomic, Doesn't make sense 
        \item Atomic vs. Shared Memory
        \item Coarse vs. Fine Grained Parallelism 
    \end{itemize}
}

\frame{
    \frametitle{GPU Implementation} 

}

\section{Conclusions}

\frame{
    \frametitle{Future Work}
    \begin{itemize}[<-+>]
        \item Algorithm improvements on redundancy
        \item The first node split can be precomputed -- EXPLAIN
        \item Task list/pool node merge -- EXPLAIN w/ a PICTURE
    \end{itemize}
}

\frame{
    \frametitle{CPU/GPU Heterogeneous Implementation}
    \begin{itemize}[<+->]
        \item GPU computation works well early on in the tree (when there are many instances to be bagged)
        \item Further down the tree the CPU implementation works best
    \end{itemize}
    \pause
    Can we automatically determine when to switch between the CPU and GPU implementations depending on the size of parent node being split?
    This is similar to the CPU/GPU pipe-lining approach we read about.
}

\frame{
    \begin{center}
        \Huge{Questions/Discussion}\\
    \end{center}
}

\nocite{*} % Include everything in the .bib file.
\bibliographystyle{plainnat}
\bibliography{random-forest-gpu}

% that's all, folks
\end{document}
